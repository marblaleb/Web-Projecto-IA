<!DOCTYPE html>
<html lang="es">

<head>
    <meta name="robots" content="index, follow">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="description" content="En esta web repasamos las últimas noticias sobre IA">
    <meta name="author" content="Marco Blanco, Jose Luis Pino">
    <meta name="copyright" content="MachineLearners.com">
    <meta name="keywords" content="IA, Machine Learning, Inteligencia Artificial">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="shortcut icon" href="../icons/robot_icon.png">
    <link rel="stylesheet" href="../css/stylesA.css">
    <title>The Machine Learners</title>
</head>

<body>
    <header id="header">
        <h2>La gran batalla por el liderazgo en la Inteligencia Artificial</h2>
    </header>
    <main>
        <article>
            <div class="centrar">
                <div class="cabeceras">
                    <figure>
                        <picture>
                            <source media="(max-width: 799px)" srcset="../images/600chatgpt.jpg">
                            <source media="(min-width: 800px)" srcset="../images/chatgpt.jpg">
                            <img src="../images/chatgpt.jpg" alt="ChatGPT">
                        </picture>
                        <figcaption>Imagen con el logotipo de chatGPT</figcaption>
                    </figure>
                </div>
                <p> <strong>OpenAI</strong> es una fundación originada por <cite><strong>Elon Musk</strong></cite> y ahora muy
                    apoyada por Microsoft, entre otros, que promueve la
                    investigación y desarrollo de redes neuronales de última generación con alto impacto en la sociedad. Aunque
                    OpenIA es sin ánimo de lucro, es obvio que todos los que participan vislumbran unas enormes posibilidades de
                    negocio.</p>
        
                <p>Su mas reciente logro, <strong>ChatGPT</strong> basado en <mark>GPT-3.5</mark>, acapara todas las portadas y
                    todo
                    el protagonismo de la
                    Inteligencia Artificial en las últimas semanas.</p>
                <p>este algoritmo, que permite responder en modo conversacional a cualquier pregunta con respuestas acordes con
                    la
                    lógica de los datos e idiomas con los que se ha entrenado, provoca furor y sorprende por la frescura y
                    espontaneidad de sus respuestas.</p>
                <p>Sus derivaciones con <strong>Dall E2</strong> llevan a plantear imágenes realistas a partir de descripciones
                    en
                    texto lo cual
                    permite idear cualquier tipo de imagen o, por ejemplo, completar imágenes de las que sólo tenemos una
                    parcialidad, en el caso de pinturas o cuadros.</p>
                <h2>Algoritmos auto supervisados <strong>tipo BERT</strong></h2>
                <p>Primero de todo, el surgimiento de algoritmos auto supervisados tipo BERT (bidirectional encoder
                    representations
                    from transformers) que surgen de Google en 2018 para interpretar mejor nuestras búsquedas y superar el 85%
                    de
                    respuesta a las consultas realizadas. Recordemos que Google lleva indexando la web desde hace más de dos
                    décadas, y de esto sabe un poco. La idea de Google con BERT es que interprete contextos, no solo palabras de
                    búsqueda, para así afinar más. Hay que tener en cuenta que cada día se hacen un 15% de búsquedas nuevas, que
                    nunca se habían visto.</p>
                <p>Desde que BERT nace en <strong>Google AI Research</strong> provoca una mejora en casi dos decenas de
                    problemas
                    que surgían con el
                    procesamiento de lenguaje natural. El secreto de BERT viene del principio acuñado en los 60 por Rupert
                    Firth,
                    quien decía que se puede conocer el significado de una palabra solo por las que tiene alrededor. En su
                    entrenamiento, la paternidad de Google hace que el algoritmo salga potenciado por el increíble entrenamiento
                    de
                    todo su patrimonio lingüístico, lo que le hace poderoso e imbatible.</p>
                <p>Usa <strong><q>Transformers</q></strong>, que es un modelo de red neuronal que data de 2017 y que supera a
                    las
                    redes neuronales
                    recurrentes que presentaban problemas con el texto y el lenguaje, sobre todo con párrafos largos. Los
                    Transformers miden los pesos de cada palabra dentro de cada oración y de su relación, por lo que llega un
                    momento que es capaz de predecir la siguiente palabra. Estos sí pueden entrenarse con párrafos largos y son
                    ideales para traducciones. GPT-3.5 por ejemplo se entrenó con 45 TB de texto de toda la web, lo cual le da
                    una
                    gran potencia, y por lo que sabemos, su próxima versión GPT-4 será mucho mas potente.</p>
                <p>En definitiva, BERT es el modelo más “popular” de todos los Transformers y constituye un modelo entrenado en
                    sí
                    mismo por investigadores de Google con un corpus de texto masivo. Pero, a raíz de BERT han surgido
                    derivaciones
                    como RoBERTa que es usado por Facebook, DistilBERT o XLNet, que mejoran rendimiento y capacidad de cómputo y
                    usan diferentes entrenamientos. En realidad, todos ellos resuelven las mismas tareas:</p>
                <ul>
                    <li>Resumen de textos.</li>
                    <li>Respuestas a preguntas.</li>
                    <li>Clasificación y resolución de entidades con nombre.</li>
                    <li>Búsqueda de textos similares.</li>
                    <li>Detección de fakes o mensajes malignos.</li>
                    <li>Entendimiento conversacional con el usuario.</li>
                </ul>
        
                <p>El segundo punto importante es que BERT y toda esta familia de <b>Transformers bidireccionales</b> son de
                    código
                    abierto,
                    lo cual significa que cualquiera puede partir del mismo, mejorarlo y compartirlo. Esta inteligencia
                    colectiva
                    hace que este algoritmo enseguida evolucione rápidamente y mute a la velocidad de virus, por lo que cada 6,
                    9 o
                    12 meses
                    salen versiones diferentes que logran saltos rupturistas. Ahora ya vamos a por <b>GPT-4</b>.</p>
        
                <p>El modelo GPT-3.5 creado por OpenAI ha conseguido popularizarse por su fácil acceso,
                    totalmente libre, y por su conversación tan realista, pero también hay que considerar
                    que Google Research ya lanzó <b>Meena</b> en 2022, también basado en Transformers, que mantiene
                    un diálogo muy convincente sobre cualquier tema. La diferencia estriba en su acceso y popularización
                    a través de TensorFlowHub, quizá menos amigable para el público, o en la biblioteca de HuggingFace,
                    mucho más atractiva, y si tienes conocimientos de programación Python, se aprovecha más y es capaz
                    de adaptarse a cualquier necesidad concreta, como crear y vender producto.</p>
        
                <p>En la base, la arquitectura técnica de funcionamiento siempre es la misma,
                    solo que OpenAI, ha evolucionado el modelo de forma exponencial desde la aparición
                    de la primera versión de GPT-1. Ahora con la próxima de GPT-4 afina y resuelve muchos
                    de los problemas detectados con ChatGPT (GPT-3.5).</p>
                <figure>
                    <picture>
                        <source media="(max-width: 799px)" srcset="../images/350openAI.jpg">
                        <source media="(min-width: 800px)" srcset="../images/openai.jpeg">
                        <img src="../images/openai.jpeg" alt="OpenAI">
                    </picture>
                    <figcaption>Proyectos de Azure</figcaption>
                </figure>
        
        
                <p>Mejoraen precisión, mayor potencia en la generación de textos y respuestas a preguntas muy difíciles.
                    En realidad, se pareceenormemente al comportamiento humano en cuanto al tipo de respuesta, de tal
                    forma que habrá un 65% de usuarios que no distinguirán quien hay detrás. Para hacernos una idea de
                    cada salto rupturista, GPT-4 será 600 veces más potente que su predecesor GPT-3.5, que es la base
                    de ChatGPT. Le quedan pocos meses para salir a la luz, pero casi seguro será antes que acabe 2023.</p>
        
                <p>Por otro lado, la base de Transformer también se usa para componer música, generar imágenes a
                    partir de texto, texto a partir de imágenes…. por lo que sus posibilidades, combinadas, son
                    inmensas. Desde un punto de vista de negocio, imaginación al poder. Las posibilidades de
                    generar productos con esta base que resuelvan problemas de empresas y ciudadanos son inmensas.</p>
        
                <p>En definitiva, para los que de alguna manera nos dedicamos a la IA desde hace más de una década,
                    lo que ocurre ahora era previsible, dado que los sistemas conversacionales ya existen desde hace tiempo
                    y su evolución y mejora es continua. Casi cada año se producen avances significativos o disrupciones que,
                    en algunos casos, cambian el estado del arte.</p>
        
                <p>En definitiva, automatizar un perfecto entendimiento del lenguaje hace que no notemos quién está detrás
                    abre una puerta enorme en numerosos campos que pueden ayudar a mejorar el mensaje, adaptarlo al receptor,
                    lograr mayores objetivos de persuasión, y todo ello sin necesidad de preparación, porque se puede realizar
                    al mismo tiempo que se habla, en tiempo real.</p>
        
                <p>Por ejemplo, podemos asegurar que un call center especializado podría automatizar totalmente su actividad a
                    través
                    de un algoritmo, cuyo desempeño sería idéntico al trabajador mejor preparado. Eso sí, siempre actuará de
                    acuerdo
                    con el entrenamiento realizado y con la información y datos proporcionados. A partir de aquí, pensemos en la
                    desaparición de botones o palancas, dado que todo lo accionaremos por voz, desde la conducción hasta las
                    maniobras en una refinería. Si, además, se combina con gemelos digitales, todo se podrá realizar desde el
                    sofá sentados con unas gafas tipo Oculus.</p>
        
                <p>En resumen, podríamos hablar de múltiples ejemplos de un uso benigno de estas tecnologías,
                    de gran ayuda al desarrollo de la humanidad porque nos hacen la vida más cómoda. Pero en el
                    lado oscuro también son muy eficaces. Da para un siguiente capítulo.</p>
        
                <iframe width="560" height="315" src="https://www.youtube.com/embed/4jrjo-Vlfs4" title="YouTube video player"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                    allowfullscreen></iframe>
        
                <div class="volver">
                    <a href="../index.html#articulo1Noticia"><img src="../images/back-button-icon.png"
                            alt="Vuelva a la página principal"></a>
                </div>
            </div>
        </article>
    </main>
    <footer>
        <p>Alumno1: Jose Luis Pino</p>
        <p>Alumno2: Marco A. Blanco Lebrón</p>
        <p>Asignatura: Lenguajes de marcas</p>
        <p>Curso: 2022-2023</p>
        <div id="UpButton"><a href="#header">^</a></div>
    </footer>

</body>

</html>